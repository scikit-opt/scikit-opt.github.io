## 代码仓库

[代码仓库](https://github.com/guofei9987/scikit-opt)  
请顺手点个star，比心

## 安装

```bash
pip install scikit-opt
```
如果嫌麻烦，直接把源代码中的 `sko` 文件夹下载下来调用即可

## 第一个遗传算法
```python
demo_func=lambda x: x[0]**2 + x[1]**2 + x[2]**2
ga = GA(func=demo_func,n_dim=3, max_iter=500, lb=[-1, -10, -5], ub=[2, 10, 2])
best_x, best_y = ga.fit()
```
恭喜，你已经跑完了第一个遗传算法！

## 自定义算子UDF
**UDF** (用户自定义算子, user defined function) 会在0.2版本可用。  

例如，如果你想到一种 `选择算子`(`selection`)，你的算子是这样的：（简单地说，就是保证最优的精英一定生存而不是经典遗传算法的大概率生存）  
改进的
```python
def selection_elite(self, FitV):
    '''
    保证最优的精英一定生存，
    而不是经典遗传算法的精英大概率生存
    '''
    print('udf selection actived')

    FitV = (FitV - FitV.min()) / (FitV.max() - FitV.min() + 1e-10) + 0.2
    # the worst one should still has a chance to be selected
    # the elite(defined as the best one for a generation) must survive the selection
    elite_index = np.array([FitV.argmax()])

    # do Roulette to select the next generation
    sel_prob = FitV / FitV.sum()
    roulette_index = np.random.choice(range(self.size_pop), size=self.size_pop - 1, p=sel_prob)
    sel_index = np.concatenate([elite_index, roulette_index])
    self.Chrom = self.Chrom[sel_index, :]  # next generation
    return self.Chrom
```

把你的 UDF 自定义算子注册到遗传算法上：
```python
from sko.GA import register_udf
GA_1 = register_udf({'selection': selection_elite})
```

像往常一样运行遗传算法：
```python
demo_func = lambda x: x[0] ** 2 + (x[1] - 0.05) ** 2 + x[2] ** 2
ga = GA_1(func=demo_func, n_dim=3, max_iter=500, lb=[-1, -10, -5], ub=[2, 10, 2])
best_x, best_y = ga.fit()
#
print('best_x:', best_x, '\n', 'best_y:', best_y)
```
恭喜你，成功了。  
（额外发现，精英策略选择算子似乎的确比传统的选择算子效果要好）

> 现在 **udf** 支持遗传算法的这几个算子：   `crossover`, `mutation`, `selection`, `ranking`


## 打赏


[打赏](https://guofei9987.github.io/donate/)
